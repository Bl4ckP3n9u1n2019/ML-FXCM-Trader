{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from bayes_opt import BayesianOptimization\n",
    "sns.set()\n",
    "from pprint import pprint\n",
    "import json\n",
    "import fxcmpy\n",
    "from sklearn import svm\n",
    "from IPython import get_ipython\n",
    "ipy = get_ipython()\n",
    "if ipy is not None:\n",
    "    ipy.run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(data, t, n):\n",
    "    d = t - n + 1\n",
    "    block = data[d : t + 1] if d >= 0 else -d * [data[0]] + data[0 : t + 1]\n",
    "    res = []\n",
    "    for i in range(n - 1):\n",
    "        res.append(block[i + 1] - block[i])\n",
    "    return np.array([res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN ='8ea6466c9b90a9716bd26056a699639309f25fc4' #copy and paste access token from FXCM\n",
    "con = fxcmpy.fxcmpy(access_token=TOKEN, log_level='error')\n",
    "con.is_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Account ID')\n",
    "# Account = con.get_account_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Open Orders')\n",
    "# order_ids =con.get_order_ids()\n",
    "# print(order_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Choose Instrument to trade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruments = con.get_instruments()\n",
    "# print(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticker = str(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bars = str(input('Choose Bar Period' '\\nMust be m1, m5, m15, m30, H1, H2, H3, H4, H6, H8, D1, W1 or M1: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop this update of candles every X minutes once the best optimisation has run\n",
    "# Maybe save this this data to a table and append with each new update\n",
    "# Maybe fork process to split Parent and Child process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = con.get_candles('AUD/USD', period='m15', number=500)\n",
    "except ValueError:\n",
    "        print('Please Check Instrument or Period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = df.bidclose.values.tolist()\n",
    "window_size = 30\n",
    "skip = 5\n",
    "l = len(close) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Evolution_Strategy:\n",
    "\n",
    "    inputs = None\n",
    "\n",
    "    def __init__(\n",
    "        self, weights, reward_function, population_size, sigma, learning_rate\n",
    "    ):\n",
    "        self.weights = weights\n",
    "        self.reward_function = reward_function\n",
    "        self.population_size = population_size\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _get_weight_from_population(self, weights, population):\n",
    "        weights_population = []\n",
    "        for index, i in enumerate(population):\n",
    "            jittered = self.sigma * i\n",
    "            weights_population.append(weights[index] + jittered)\n",
    "        return weights_population\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def train(self, epoch = 100, print_every = 1):\n",
    "        lasttime = time.time()\n",
    "        for i in range(epoch):\n",
    "            population = []\n",
    "            rewards = np.zeros(self.population_size)\n",
    "            for k in range(self.population_size):\n",
    "                x = []\n",
    "                for w in self.weights:\n",
    "                    x.append(np.random.randn(*w.shape))\n",
    "                population.append(x)\n",
    "            for k in range(self.population_size):\n",
    "                weights_population = self._get_weight_from_population(\n",
    "                    self.weights, population[k]\n",
    "                )\n",
    "                rewards[k] = self.reward_function(weights_population)\n",
    "            rewards = (rewards - np.mean(rewards)) / np.std(rewards)\n",
    "            for index, w in enumerate(self.weights):\n",
    "                A = np.array([p[index] for p in population])\n",
    "                self.weights[index] = (\n",
    "                    w\n",
    "                    + self.learning_rate\n",
    "                    / (self.population_size * self.sigma)\n",
    "                    * np.dot(A.T, rewards).T\n",
    "                )\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print(\n",
    "                    'iter %d. reward: %f'\n",
    "                    % (i + 1, self.reward_function(self.weights))\n",
    "                )\n",
    "        print('time taken to train:', time.time() - lasttime, 'seconds')\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_size, layer_size, output_size):\n",
    "        self.weights = [\n",
    "            np.random.randn(input_size, layer_size),\n",
    "            np.random.randn(layer_size, output_size),\n",
    "            np.random.randn(layer_size, 1),\n",
    "            np.random.randn(1, layer_size),\n",
    "        ]\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        feed = np.dot(inputs, self.weights[0]) + self.weights[-1]\n",
    "        decision = np.dot(feed, self.weights[1])\n",
    "        buy = np.dot(feed, self.weights[2])\n",
    "        return decision, buy\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        population_size,\n",
    "        sigma,\n",
    "        learning_rate,\n",
    "        model,\n",
    "        money,\n",
    "        max_buy,\n",
    "        max_sell,\n",
    "        skip,\n",
    "        window_size,\n",
    "    ):\n",
    "        self.window_size = window_size\n",
    "        self.skip = skip\n",
    "        self.POPULATION_SIZE = population_size\n",
    "        self.SIGMA = sigma\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.model = model\n",
    "        self.initial_money = money\n",
    "        self.max_buy = max_buy\n",
    "        self.max_sell = max_sell\n",
    "        self.es = Deep_Evolution_Strategy(\n",
    "            self.model.get_weights(),\n",
    "            self.get_reward,\n",
    "            self.POPULATION_SIZE,\n",
    "            self.SIGMA,\n",
    "            self.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "    def act(self, sequence):\n",
    "        decision, buy = self.model.predict(np.array(sequence))\n",
    "        return np.argmax(decision[0]), int(buy[0])\n",
    "\n",
    "    def get_reward(self, weights):\n",
    "        initial_money = self.initial_money\n",
    "        starting_money = initial_money\n",
    "        self.model.weights = weights\n",
    "        state = get_state(close, 0, self.window_size + 1)\n",
    "        inventory = []\n",
    "        quantity = 0\n",
    "        for t in range(0, l, self.skip):\n",
    "            action, buy = self.act(state)\n",
    "            next_state = get_state(close, t + 1, self.window_size + 1)\n",
    "            if action == 1 and initial_money >= close[t]:\n",
    "                if buy < 0:\n",
    "                    buy = 1\n",
    "                if buy > self.max_buy:\n",
    "                    buy_units = self.max_buy\n",
    "                else:\n",
    "                    buy_units = buy\n",
    "                total_buy = buy_units * close[t]\n",
    "                initial_money -= total_buy\n",
    "                inventory.append(total_buy)\n",
    "                quantity += buy_units\n",
    "            elif action == 2 and len(inventory) > 0:\n",
    "                if quantity > self.max_sell:\n",
    "                    sell_units = self.max_sell\n",
    "                else:\n",
    "                    sell_units = quantity\n",
    "                quantity -= sell_units\n",
    "                total_sell = sell_units * close[t]\n",
    "                initial_money += total_sell\n",
    "\n",
    "            state = next_state\n",
    "        return ((initial_money - starting_money) / starting_money) * 100\n",
    "\n",
    "    def fit(self, iterations, checkpoint):\n",
    "        self.es.train(iterations, print_every = checkpoint)\n",
    "\n",
    "    def buy(self):\n",
    "        initial_money = self.initial_money\n",
    "        state = get_state(close, 0, self.window_size + 1)\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        quantity = 0\n",
    "        profit = 0\n",
    "        loss = 0\n",
    "        for t in range(0, l, self.skip):\n",
    "            action, buy = self.act(state)\n",
    "            next_state = get_state(close, t + 1, self.window_size + 1)\n",
    "            if action == 1 and initial_money >= close[t]:\n",
    "                if buy < 0:\n",
    "                    buy = 1\n",
    "                if buy > self.max_buy:\n",
    "                    buy_units = self.max_buy\n",
    "                else:\n",
    "                    buy_units = buy\n",
    "                total_buy = buy_units * close[t]\n",
    "                initial_money -= total_buy\n",
    "                inventory.append(total_buy)\n",
    "                quantity += buy_units\n",
    "                states_buy.append(t)\n",
    "                print(\n",
    "                    'day %d: buy %d units at price %f, total balance %f'\n",
    "                    % (t, buy_units, total_buy, initial_money)\n",
    "                )\n",
    "            elif action == 2 and len(inventory) > 0:\n",
    "                bought_price = inventory.pop(0)\n",
    "                if quantity > self.max_sell:\n",
    "                    sell_units = self.max_sell\n",
    "                else:\n",
    "                    sell_units = quantity\n",
    "                if sell_units < 1:\n",
    "                    continue\n",
    "                quantity -= sell_units\n",
    "                total_sell = sell_units * close[t]\n",
    "                initial_money += total_sell\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((total_sell - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print(\n",
    "                    'day %d, sell %d units at price %f, investment %f %%, total balance %f,'\n",
    "                    % (t, sell_units, total_sell, invest, initial_money)\n",
    "                )\n",
    "                if invest > 0:\n",
    "                    profit += 1\n",
    "                else:\n",
    "                    loss += 1\n",
    "            state = next_state\n",
    "\n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        ratio = (profit / (loss + profit)) * 100\n",
    "        print(\n",
    "            '\\ntotal gained %f, total investment %f %%'\n",
    "            % (initial_money - starting_money, invest)\n",
    "        )\n",
    "        print(\n",
    "            'total wins %d , total losses %d, accuracy ratio: %f'\n",
    "            % (profit , loss , ratio)\n",
    "            )\n",
    "        print('left in inventory: %d' % (len(inventory)))\n",
    "        print(inventory)\n",
    "        print('\\nPredicted Buy/Sell for ' +str(len(close))+ ' ROI: ' + str(int(invest))+'%')\n",
    "        plt.figure(figsize = (20, 10))\n",
    "        plt.plot(close, label = 'true close', c = 'g')\n",
    "        plt.plot(\n",
    "            close, 'X', label = 'predict buy', markevery = states_buy, c = 'b'\n",
    "        )\n",
    "        plt.plot(\n",
    "            close, 'o', label = 'predict sell', markevery = states_sell, c = 'r'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_agent(\n",
    "    window_size, skip, population_size, sigma, learning_rate, size_network\n",
    "):\n",
    "    model = Model(window_size, size_network, 3)\n",
    "    agent = Agent(\n",
    "        population_size,\n",
    "        sigma,\n",
    "        learning_rate,\n",
    "        model,\n",
    "        10000,\n",
    "        5,\n",
    "        5,\n",
    "        skip,\n",
    "        window_size,\n",
    "    )\n",
    "    try:\n",
    "        agent.fit(10, 1000)\n",
    "        return agent.es.reward_function(agent.es.weights)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_agent(\n",
    "    window_size, skip, population_size, sigma, learning_rate, size_network\n",
    "):\n",
    "    global accbest\n",
    "    param = {\n",
    "        'window_size': int(np.around(window_size)),\n",
    "        'skip': int(np.around(skip)),\n",
    "        'population_size': int(np.around(population_size)),\n",
    "        'sigma': max(min(sigma, 1), 0.0001),\n",
    "        'learning_rate': max(min(learning_rate, 0.5), 0.000001),\n",
    "        'size_network': int(np.around(size_network)),\n",
    "    }\n",
    "    print('\\nSearch parameters %s' % (param))\n",
    "    investment = best_agent(**param)\n",
    "    print('stop after 100 iteration with investment %f' % (investment))\n",
    "    if investment > accbest:\n",
    "        costbest = investment\n",
    "    return investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accbest = 0.0\n",
    "NN_BAYESIAN = BayesianOptimization(\n",
    "    find_best_agent,\n",
    "    {\n",
    "        'window_size': (2, 50),# Baseline: 2,50\n",
    "        'skip': (1, 15), # Baseline: 1, 15\n",
    "        'population_size': (1, 50),# Baseline: 1, 50\n",
    "        'sigma': (0.01, 0.99),\n",
    "        'learning_rate': (0.000001, 0.49),# Baseline: 0.000001 , 0.49\n",
    "        'size_network': (10, 1000),# Baseline: 10, 1000\n",
    "    },\n",
    ")\n",
    "NN_BAYESIAN.maximize(init_points =30, n_iter = 50, acq = 'ei', xi = 0.0) # Baseline: init_points=30 n_iter=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best AGENT accuracy value: %f' % NN_BAYESIAN.res['max']['max_val'])\n",
    "print('Best AGENT parameters: ', NN_BAYESIAN.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_res = str(NN_BAYESIAN.res['max']['max_params'])\n",
    "bayes_res = json.loads(bayes_res.replace(\"'\", \"\\\"\"))\n",
    "bayes_res['window_size'] = int(round(bayes_res['window_size']))\n",
    "bayes_res['skip'] = int(round(bayes_res['skip']))\n",
    "bayes_res['population_size'] = int(round(bayes_res['population_size']))\n",
    "bayes_res['size_network'] = int(round(bayes_res['size_network']))\n",
    "pprint(bayes_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 = Funds or Margin, Buy / Sell = 200 , 200\n",
    "model = Model(bayes_res['window_size'], bayes_res['size_network'], 3)\n",
    "agent = Agent(\n",
    "    bayes_res['population_size'], bayes_res['sigma'], bayes_res['learning_rate'], model, 10000, 200, 200, bayes_res['skip'], bayes_res['window_size']\n",
    ")\n",
    "agent.fit(bayes_res['size_network'], 100)\n",
    "agent.buy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
